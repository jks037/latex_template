\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[numbers]{natbib}
\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{bm}
\usepackage{booktabs}
\usepackage{subfig}
\usepackage[colorlinks,linkcolor=blue]{hyperref}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex. (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
%\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi
%\setcounter{page}{4321}
\begin{document}

%%%%%%%%% TITLE
%%%%%%%%% TITLE
\title{A weak-shot classification practice based on generalized cross-entropy loss and modified sample weighting}


\author{$\textnormal{Honghao Chen}^{*}$, $\textnormal{Tianyi Zhou}^{*}$\\
$^*$ Shanghai Jiao Tong University \\
}

\maketitle
\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
Midterm report for Statistical Learning and Inference course.
\end{abstract}

%%%%%%%%% BODY TEXT

\section{Introduction}

Deep learning has been successefully applied to a variaty of computer vision researchs and huge amout of powerful tools. However, the training of deep learning models relies much on well labeled datases. Though large commertial entities such as Google and Alibaba investigate a lot on collection of data sets, considering the endless fine-grained categories, the lack of well-labeled data sets is inevitable. A strategy alleviates this data-hungry problem called weakly-shot learning~\cite{chen2020weak} is to first gain informations from  fully-annotated training samples (base categories), then transfer the gained information to novel categories which have little or even no overlap with the original training samples.Previous research on this topic includes zero-shot learning, few-shot learning and weakly-supervised learning. 

%zero-shot and few-shot learning intro, re-write this paragraph
Zero-shot learning and few-shot learning attempt to utility training samples with limited quantities. To solve the problem of distiction between base categories and nove categories, zero-shot learning extract category-leve semantic representations such as word vectors for all categories. Few-shot learning gains clue from small-sized clean examples (for example 5 or 10) in novel categories. Though succeed in some categories, they have several disadvantages:1.Annotating attributes needed for zero-shot learning and well-labeled samples (even few) are not always available;2.Attributes like word vectors are free, but are sometimes ambiguous due to the nature of language (for example one word has multiple meanings). These will affect the final effectiveness of training.

Webly-supervised learning is another category of method trying to solve the problem of data-hunger problem. At the first place, it is invented for a cool task of learning everything about anything~\cite{Divvala2014} by utilizing search engines for gains of training data. Huge amount of images is easily found this way with low cost with the cost of quality. Main challenge of webly-supervised learning is how to take use of these huge data of low quality. Methods proposed include improving the quality through image-process technologies~\cite{Liu2014,Xia2015}, designing specified training method to reduce the negative effect of noise~\cite{Volodymyr2012,NEURIPS2018_f2925f97,Patrini2017,Zhuang2017}, and so on~\cite{SunCY19,YaoW0T019,KrauseSHZTDPF16}.

Weak-shot learning is one kind weakly supervised learning that utilizing auxiliary fully supervised base categories. Several types of weak-shot learning are under consistent research. Weak-Shot Object Detection focus on providing bounding boxes for fine-grained categories. Main idea of methods propsed~\cite{NIPS2014_09fb05dd,KuenPLZT19,RochanW15} is to transfers information gained from bounding box annotated data to classifiers for categories without them. Similarly, Weak-Shot instance segmentation transfers information gained from mask annotated data to training on box annotated data. Methods proposed accomplish this transfer by weight transfer function~\cite{Hu2018LSET}, shape priors~\cite{Kuo2019}, and instance saliency~\cite{Zhou2020Sal}.

%some other related works. the pharagragh below is completely copied, remain to be replaced
%Considering the drawbacks of zero/few-shot learning and the accessibility of free web data, we intend to learn novel categories by virtue of web data with the support of a clean set of base categories, which is referred to as weak-shot learning as illustrated in Figure 1. Formally, given a set of novel fine-grained categories which are not associated with any clean training images, we collect web images for novel categories as weak-labeled images and meanwhile leverage the clean images from base fine-grained categories. We refer to the clean (resp., web) image set from base (resp., novel) categories as base (resp., novel) training set. The closest related work to ours is (Niu, Veeraraghavan, and Sabharwal 2018), but they further assumed the reliability of word vectors (Mikolov et al. 2013; Pennington, Socher, and Manning arXiv:2009.09197v1 [cs.CV] 19 Sep 2020 2014) as well as the availability of unlabeled test images in the training stage. In this learning scenario, the key issue of novel training set is label noise, which will significantly degrade the performance of learnt classifier (Niu, Veeraraghavan, and Sabharwal 2018; Zhuang et al. 2017; Patrini et al. 2017; Zhang, Wang, and Qiao 2019). We explore using base training set to denoise novel training set, although they have disjoint category sets. As illustrated in Figure 2, our proposed frame-work employs the pairwise semantic similarity to bridge the gap between base categories and novel categories. The pairwise similarity which denotes whether two images belong to the same category is category-agnostic, so it is highly transferable across category sets even if they are disjoint. Meanwhile, the pairwise similarity can be easily learnt fromlimited data, indicating that a small set of already annotated images could help learn extensive novel categories. Analogously, some methods (Chen et al. 2020; Oreshkin, Lopez, and Lacoste 2018) for few-shot learning transferred similarity from base categories to novel categories, which is directly used for classification. In contrast, we transfer the pairwise similarity to alleviate the label noise issue of web data. For learning from web data, some works (Sheng Guo and Huang 2018; Han, Luo, and Wang 2019) also attempted to denoise by similarity. But their similarities are derived from noisy samples (e.g., feature distances of a model pre-trained on web data), and likely to be corrupted due to noise overfitting, leading to sub-optimal results (Kuang-Huei Lee and Yang 2018; Xiao et al. 2015).

% introduction to method and concludes
In Weak-shot classification, the knowledge to transfer is the similarity trained in base data~\cite{chen2020weak}. We utilize generalized cross-entropy loss~\cite{NEURIPS2018_f2925f97} to deal with general label-noise in novel set, which is a generalized form of cross-entropy loss adding (CCE) noise-tolerate feature of mean absolute error (MAE). We also applied truncated sample weighting to effectively eliminate outliers. This weighting is modified from the prior form~\cite{chen2020weak} by treated images with largest mutual similarities equally as well-labeled ones, while excluding those with least siliarites as outliers. Mutual similarities are computed via pre-trained similarity net, which transfer the knowledge gained from base set to novel set.
The experiments are under conducting before results' release. 


\section{Related Works}
\label{section:related}
Weak-shot classification is a new conception with few article available. In this section we introduce related work from two aspects.Section~\ref{section:related:zero} to Section~\ref{section:related:webly} introduce similar methods attempt to lower the requirement of training samples.Section~\ref{section:related:weakDtct} to Section~\ref{section:related:seg} introduce other applications of weak-shot learning bisides weak-shot classification.

\subsection{Zero-Shot learning}
\label{section:related:zero}
A series of major progresses in visual object recognition can largely be attributed to learning large-scale and complex models with a huge number of labeled training images.There are many application scenarios, however, where collecting and labeling training instances can be laboriously difficult and costly. Under such circumstances, zero-shot learning employs category-level semantic representation to bridge the gap between seen categories and unseen categories~\cite{ChangpinyoCS17}. It is to use the past knowledge to infer the specific form of the new object in the mind, so as to identify the new object. ZSL hopes to imitate the reasoning process of human beings and make the computer have the ability to recognize new things.The training set data is used to train the model, so that the model can classify the objects of the test set, but there is no intersection between the training set categories and the test set categories; In order to make the model effective, we need to establish the relationship between training set and test set with the help of category description.What we need to do is to establish the mapping between feature space and semantic space~\cite{FuHXG15}. There is domain drift problem in ZSL. In short, it is the same attribute. In different categories, the performance of visual features may be very large. Both zebra and pig have tails, so in its category semantic representation, "with tail" is a non-zero value, but the visual characteristics of their tails are very different. If zebra is a training set and pig is a test set, it is difficult to classify pigs correctly by using the model trained by zebra~\cite{KodirovXG17}. Self coding tools are generally used to solve this problem. Because the feature dimension of samples is often larger than the semantic dimension, information is often lost when establishing the mapping from feature dimension to semantics. In order to retain more information and maintain more richness, the most popular method is to map the samples in the semantic space and rebuild them, In this way, the learned mapping can retain more information.In addition, there is also the problem of semantic gap. The features of samples are often visual features, such as the features extracted by depth network, but the semantic representation is non visual, which directly reflects the data. In fact, the flow pattern formed by samples in feature space is inconsistent with that formed by categories in semantic space~\cite{LiWHLZ17}. The essence of semantic gap problem is that their manifold structures are inconsistent. Therefore, the starting point to solve this problem is to adjust their manifolds to be consistent, and then learn the mapping between them.

\subsection{Few-Shot learning}
\label{section:related:few}
When creating a new conversation task, a large number of platform users do not have a large amount of annotation data, and each intention often has only a few or more samplesï¼ŒFew shot learning is to solve these problems~\cite{SantoroBBWL16}.Santoro et al. proposed the use of memory enhancement to solve the feed shot learning task. Memory based neural network method was proved to be used in meta learning as early as 2001. They adjust bias through weight updates and adjust output by learning to cache expressions into memory~\cite{koch2015siamese}.The Siamese network is trained to learn in a supervised way, and then the features extracted by the network are reused for one / feed shot learning.The specific network is a two-way neural network. During training, different paired samples are constructed by combination, input into the network for training, judge whether they belong to the same class through the distance of sample pairs at the top layer, and generate the corresponding probability distribution. In the prediction stage, Siamese network processes each sample pair between the test sample and the support set, and the final prediction result is the category with the highest probability on the support set~\cite{vinyals2016matching}.The match network constructs different encoders for the support set and the batch set. The final output of the classifier is the weighted sum of the predicted values between the support set samples and the query~\cite{snell2017prototypical}.Prototype network is based on the idea that there is a prototype expression for each category, and the prototype of this category is the mean value of support set in embedding space. Then, the classification problem becomes the nearest neighbor in embedded space~\cite{finn2017model}. Finn's method makes it possible to obtain better generalization performance with a small number of iterative steps on a small number of samples, and the model is easy to fine tine. Moreover, this method does not need to care about the form of the model, nor does it need to add new parameters to meta learning, and directly uses gradient descent to train learners.

\subsection{Webly-supervised learning}
\label{section:related:webly}
The conception of webly-supervised learning is first invented for a learning method gathering target pictures satisfying given quiries automatically from web search engines which are used to train virtual models telling whether a given picture is consistent with a given concept~\cite{Divvala2014}. Though not the main aim, its usage of pictures gathered from Internet hint a solution for data hungry problem. However, though huge amount of pictures are gathered this way, the quality of them are out of control. Many methods have been proposed to deal with this problem. Outlier removal ~\cite{Liu2014,Xia2015} improve the quality images by remove probable noise pixels. Some research proposed robust loss functions ~\cite{Volodymyr2012,NEURIPS2018_f2925f97} for replacement of traditional loss function when the datasets are noisy. Another modified training method proposed is to correct the loss computed in training process affected by noise ~\cite{Patrini2017,Veit2017}. Also, applying noise cancel strategies such as random grouping to reduce the negative effect of noise ~\cite{Zhuang2017,Zhang2019} improves the performance of training. Besides, many other methods deal with faults in datasets are proposed ~\cite{SunCY19,YaoW0T019,KrauseSHZTDPF16}.

\subsection{Weak-Shot Object Detection}
\label{section:related:weakDtct}
Object detection aims at giving bonding boxes in images. When applying weak-shot learning to object detection, researchers try transfer information gained from datasets with bounding boxes to training based on dataset with only image labels.
First work on this topic is Large Scale Detection through Adaptation  (LSDA)~\cite{NIPS2014_09fb05dd}. LSDA learns the difference between the two tasks and transfers this knowledge to classifiers for categories without bounding box annotated data. Many methods~\cite{KuenPLZT19,RochanW15} follow similar idea of transfering information gained from bounding box annotated data and difference between target categories.

\subsection{Weak-Shot Instance Segmentation}
\label{section:related:seg}
Instance segmentation can be regarded as a more advanced opject detection which masks target objects rather than just box them. Applications of this kind, for example Mask RCNN~\cite{Hu2018LSET}, kind appear just recently. Weak-Shot instance segmentation transfer knowledge gained from mask annotated data to training using only box anotated data.
Mask RCNN~\cite{Hu2018LSET} introduces a novel weight transfer function to accomplish the knowledge tranformation. ShapeMask~\cite{Kuo2019} trains a set of shape bases from mask annotations called shape priors, then applies them into training on novel categories. A more recent work~\cite{Zhou2020Sal} attempt to propagate information from its salient regions identifying module to instance segmentation module.


\section{Our Method}
We choose transfer similarity from the base training set to novel training set. Overall traning process consists of learning similarity net (SimNet) and learning classifier with the auxiliary of the trained SimNet. We follow SimilarlyTransfer~\cite{chen2020weak} when training the SimNet, and utilize SimNet and noise-robust loss function to improve the performance of classifier trained on novel data set. The first step is demonstrated in section ~\ref{section:method:simnet}, second step in section ~\ref{section:method:class}.

\subsection{Learning Similarity on Fine-annotated Training Set}
\label{section:method:simnet}

\subsection{Learning Classifier on Noisy Training Set}
\label{section:method:class}
Due to the errors in training labels which is common for web images, the performance is far from satisfaction when train directly. According to prior study~\cite{sukhbaatar2015training}, noise can be devided into two types: outlier noise and label-flip noise. We take advantage of pre-trained similarity net to deal with outliers and apply generalized cross-entropy loss to alleviate label-flip and other noise. We will then introduce the detailed methods, \emph{i.e.} generalized cross-entropy loss and modified sample weighting.


%\begin{itemize}
%\item 
%\noindent
\subsubsection{Generalized Cross-Entropy Loss}
\label{section:method:class:gce}
% reference: Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels
Commonly, categorical cross entropy (CCE) loss is used in training. In cases that training set is noisy, the performance is severely affected. Former research~\cite{NEURIPS2018_f2925f97} introduces a generalize cross-entropy loss modifying the traditional CCE that add noise-tolerate feature to it.
The idea is to combine mean absolute error (MAE) with CCE. MAE is a noise-robust alternative of CCE, however as a price of noise-toleration, it could perform poorly, especially when training set is challenging. The solution is to choose the negative Box-Cox transformation as a loss function:\begin{equation}\mathcal{L}_q = \cfrac{1}{B}\sum_{i=1}^{B}\cfrac{(1-f_{c,i}^{q}(x)_c)}{q}\label{eql:gloss} \end{equation} where $B$ is the batch size, $x_{c,i}$ is the \emph{i}-th image of the \emph{c}-th category, and $f_{c,i}(x)_c$ is its classification score corresponding to category c, $0 < q \leq 1$. It can be proved via L'Hospital's rule that it is equivalent to CCE for $lim_{q\rightarrow 0}\mathcal{L}_q$, and become MAE when $q=1$. This means Eq.~\ref{eql:gloss} is a generalization of cross entropy and MAE, using \emph{q} to indicate to which it is more similar. Thus this generalized cross entropy add noise-toleration of MAE  which is useful when training on a noisy data set. In our experiments, we empirically choose $q=0.7$.

%\end{itemize}
\subsubsection{Truncated Sample Weighting}
\label{section:method:class:tsw}
The transfer of knowledge gained from base set to novel set is accomplished via utilizing the pre-trained similarity net to eliminate outlier noise in novel set, following the method first propsed in the pineer work of weak-shot classification ~\cite{chen2020weak}. The plausibility that similarity can be applied to denoise infers from two trivial assumption: (1) similarity of similar fine-grained categories is almost unique; (2) outliers differs from each other while non-outliers have similar counter-parts because images belongs to the same category must look similar. The former assumption makes sure that the similarity net trained on the base data set can be applied to judge whether an image in novel set is similar to another.

For the \emph{c}-th novel category, we first compute the sililarity matrix $S_c$, whose size is $N_c^n\times N_c^n$, $N_c^n$ being the number of images belongs to \emph{c}-th novel category. This is computationally efficient as it just need to be computed once for each category. Then we compute teh average of similarities between image \emph{i} and each of the rest images:\begin{equation}w_{c,i} = \cfrac{1}{N_c^n}\sum_j^{N_c^n}\cfrac{s_{c,i,j}+s_{c,j,i}}{2}.   \label{eql:simw}\end{equation} Then we normalize this average in a truncated manner as its weight:
\begin{equation} \overline{w}_{c,i}=\begin{cases}
    1,& \text{$w_{c,i} \geq w_{c,u}$}\\
    w_{c,i}/w_{c,u},& \text{$w_{c,l}<w_{c,i}\leq w_{c,u}$}\\
    0,& \text{$w_{c,i}\leq w_{c,l}$}
\end{cases}.
\end{equation}
Here $w_{c,u}$ denotes a chosen upper threshold that, if $w_{c,i}$ overcome this, we regard the correspongding image is well-labeled, and all images satisfying this is treated equally. Similary, $w_{c,l}$ denotes a chosen lower threshold that, images with $w_{c,i}$ lower than $w_{c,l}$ are regarded as outliers to remove away from learning process. Images with intermediat values are normalized using the upper threshold. In experiment, we choose $w_{c,u}$ being the weight of 70-percent largest $w_{c,i}$, and $w_{c,l}$ being the 10-percent largest $w_{c,i}$. This is corresponding to an emperical assumption that 30-percent of images in the novel set can be regard as well-labled and 10-percent of them are outliers.

\subsection{The Full Objective}
\label{section:method:full}
On the whole, the classifier is trained on novel set by generalized cross-entropy loss combined with truncated sample weighting:
\begin{equation}\mathcal{L}_q = 
    \cfrac{1}{B}\sum_{i=1}^{B}\overline{w}_{c,i}\cfrac{(1-f_{c,i}^{q}(x)_c)}{q}\label{eql:gloss}, \end{equation} 
where we set $q=0.7$ empirically.

\section{Experiments}
Under conduction.

\section{Conclusion}
Will release after experiment accomplished.

\small
\bibliographystyle{ieee_fullname}
\bibliography{main}


\end{document}
